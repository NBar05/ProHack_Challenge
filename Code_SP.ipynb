{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для prochack турнира\n",
    "\n",
    "import os\n",
    "os.getcwd() # \"/Users/nikitabaramiya/\"\n",
    "#os.chdir(\"/Users/nikitabaramiya/Desktop/prohack_dataset\")\n",
    "os.chdir(\"C:\\\\Users\\\\msi\\\\Documents\\\\Sergey\\\\ML Sergey\\\\first hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from collections import Counter\n",
    "# для анализа времени работы алгоритмов\n",
    "import time\n",
    "from datetime import datetime\n",
    "# для обработки данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# для визуализации данных\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# для заполнения пропусков и стандартизации\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor # также используем в ансамбле\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# предсказательные модели\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "# ансамбли\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# ускоренная версия градиентного бустинга\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# для построения и оценивания моделей\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfWUlEQVR4nO3deXRcZ5nn8e9Tm6pkLZZteYmXOA52FpqQgEnSpCGh0zA5zABhBqZDgCF9ALNlhj7NH8OB6TM5zeHAmR7IwDTTTLZDaDppGghDgG6W7GwO2IkJWe3EcRw7jiUv2qySqured/6oW4qsSFap1nt1f59zfFRVKtd9XFF+9eq57/tec84hIiLRk2h3ASIiUhsFuIhIRCnARUQiSgEuIhJRCnARkYhKtfJgK1ascBs3bmzlIUVEIm/nzp1HnHP9Mx9vaYBv3LiRHTt2tPKQIiKRZ2bPzfa4WigiIhGlABcRiSgFuIhIRCnARUQiSgEuIhJRCnARkYhSgIuIRJQCXEQkohTgIiIR1dKVmGFx24P7Z3386os2tLgSEZHaaQQuIhJR8wa4ma03s3vN7Akze8zMPhk8fp2ZHTSzXcGftza/XBERqaimhVICPuWce8jMuoGdZvbz4HvXO+f+Z/PKExGRucwb4M65Q8Ch4PaomT0BrG12YSIicmoL6oGb2UbgAuDB4KFrzewRM7vFzPrm+DvbzGyHme0YHBysq1gREXlJ1QFuZl3A94C/dM6NAH8PnAmcT3mE/qXZ/p5z7gbn3Fbn3Nb+/pftRy4iIjWqKsDNLE05vP/ROXcHgHPusHPOc875wI3Ahc0rU0REZqpmFooBNwNPOOe+PO3xNdOe9k7g0caXJyIic6lmFsolwPuBP5jZruCxzwDvMbPzAQfsAz7SlApFRGRW1cxC+SVgs3zrXxpfjoiIVCuWS+ln8p3DuXZXISKyMFpKD9z1+GH+7wPPtLsMEZEFUYADB4fyHB6ZwGkYLiIRogAHhvNFip5jvOC1uxQRkaopwCkHOMDRsUKbKxERqV7sA3yi6DFZ8gE4cmKyzdWIiFQv9gE+Eoy+QSNwEYmW2Af48MT0ANcIXESiI/YBftII/IRG4CISHbEP8MoJzHTSOKIRuIhESOxXYg7niyzpSNGRSqgHLiKRogDPF+nNpUglEhzVLBQRiZDYB/hIvkRfZxrMNAIXkUhRDzxfpCeXpqsjyREFuIhESKxH4IWST77o0ZtLU/B8jp2YxPcdicRsu+eKiIRLrEfglSmEvbk0XR0pfAdD06YVioiEWawDfGhagC/pKP8yosU8IhIVsQ7wmSNwQH1wEYmMWPfAK8voe3Jpin55L3BNJRSRqIj1CHw4X6QzkySdTEyNwDWVUESiItYBPpIv0ptLA9CZSWKmHriIREesA3x4WoAnzFjWmeGINrQSkYiIfYD3BAEOsLwroxG4iERGbAPc88vXwOzOvnQed/mSDvXARSQyYhvgRa98GbWO5EtvwfKujPYEF5HIiH2Ap6YF+IquDu0JLiKREeMAL8/7zkwfgS/JMDpRYrLktassEZGqxTjAKyPwlzauWt7VAcAxtVFEJAJiH+DpGT1w0GIeEYmGGAd4uYWSntFCAdQHF5FIiHGAV0bgL7VQKot6RidKbalJRGQhYhvgpVlaKJVFPSMT2hNcRMJv3gA3s/Vmdq+ZPWFmj5nZJ4PHl5nZz81sT/C1r/nlNs5sLZTKoh6NwEUkCqoZgZeATznnzgEuBj5hZucCnwbuds5tBu4O7kfGbC2UXDpJKmFT+4SLiITZvAHunDvknHsouD0KPAGsBd4B3Bo87VbgymYV2QyzLeQxM7qzKY3ARSQSFtQDN7ONwAXAg8Aq59whKIc8sHKOv7PNzHaY2Y7BwcH6qm2g2RbyQLkPrh64iERB1QFuZl3A94C/dM6NVPv3nHM3OOe2Oue29vf311JjU8y2kAfQCFxEIqOqADezNOXw/kfn3B3Bw4fNbE3w/TXAQHNKbI6i50gmjISdHOA92bR64CISCdXMQjHgZuAJ59yXp33rTuADwe0PAD9ofHnNU/T9k05gVmgELiJRUc1FjS8B3g/8wcx2BY99Bvgi8M9m9kFgP/Du5pTYHMWSf9IUwoqerHrgIhIN8wa4c+6XwMuHqmWXN7ac1in5btYA786mNQIXkUiI7UrMojd7C6Unl2JssoTnuzZUJSJSvZgH+OwjcIAxjcJFJORiHOCOVGK2Hni5q6Q+uIiEXYwD3CeTmm0Wija0EpFoiHWAzzoCzwUj8LxaKCISbjEOcDf7ScxsZU9wjcBFJNxiHOBzzwMHGNFJTBEJOQX4DC/tCa4RuIiEW2wDvDRHC6US4OqBi0jYxTLAfefmXImZSibozCQ1AheR0ItlgJdmuZzadNoPRUSiIJYBPtde4BXakVBEoiDWAT7zajwVuiqPiERBTAO83EJJzRHgGoGLSBTENMBffkX66XRVHhGJgpgHuEbgIhJdMQ3weWahBD1w57QnuIiEVywDvDRPC6U7m6LoOSZLfivLEhFZkFgGeGGeFsrUfijqg4tIiMUywOdbyDO1nF59cBEJsWquSr/oFP3ZWyi3PbgfgKdeHAXguzsPsGFZJ1dftKG1BYqIVCGWI/Bi6dQtlGy6/PhE0WtZTSIiCxXPAPcrC3lmP4mZTScBBbiIhFs8A7zkkzBI2uwBnpsKcM1CEZHwimeAez6pZAKbI8A1AheRKIhngPuOdGL28Ibyyc2EKcBFJNziGeAln3Rq7n+6mZFNJ8krwEUkxOIZ4L4jnTj1Pz2bTmoELiKhFssAL3n+nMvoK3LppE5iikioxTLAC3NckX66nFooIhJysQzw8hXp52mhZJLkCwpwEQmveQPczG4xswEze3TaY9eZ2UEz2xX8eWtzy2ys8jTC+VsoGoGLSJhVMwL/BnDFLI9f75w7P/jzL40tq7mKC2ihaE9wEQmreQPcOfcAcKwFtbRMsYoWSi6TxPPd1MUfRETCpp4e+LVm9kjQYumb60lmts3MdpjZjsHBwToO1zjFKmehAGqjiEho1Rrgfw+cCZwPHAK+NNcTnXM3OOe2Oue29vf313i4xqqqhZIJAlwnMkUkpGoKcOfcYeec55zzgRuBCxtbVvM454JZKBqBi0i01RTgZrZm2t13Ao/O9dywKXg+jrn3Aq/QCFxEwm7eK/KY2e3AZcAKMzsA/HfgMjM7H3DAPuAjTayxoSYKp76YQ4VG4CISdvMGuHPuPbM8fHMTammJiVI5kKuZBw4KcBEJr9itxKy0ROYbgXekExhqoYhIeMUuwCsj8PkCPDG1payuTC8i4RS/AC/OfkX62eS0H4qIhFjsArzaFgpoPxQRCbfYBXi1LRQIAlwjcBEJqdgF+GSxEuDzt1CymSR5XdRBREIqdgFeaYnMd0k1gE61UEQkxGIX4FMnMU9xUeOKXCbJREFbyopIOMUuwKdOYiaqmIWSTuI5p1G4iIRS/AK80kKpZgQerMYcGi82tSYRkVrEL8ALHgakqhiBZ4MNrYbzCnARCZ/YBfh4wSOTSmBWXQsFFOAiEk6xC/B8sUSmijng8NKWsgpwEQmj2AX4eMGrqv8NGoGLSLjFLsDzBa/qEXhnMAIfUYCLSAjFL8CLXlWrMIFyrxyNwEUknGIX4AtpoVS2lFWAi0gYxS7AF9JCgfKJTM0DF5Ewil+AF8vTCKuV0whcREIqdgE+Xqh+GiGUR+AKcBEJoxgGuFfVXuAVuXRSs1BEJJRiF+ATaqGIyCIRqwAvej5Fzy1sBB60ULSlrIiETawCfDzYSjZT5TxwKI/AS77jhC6tJiIhE6sAn1jAVrIVndoPRURCKlYB/tIIfGEtFICh8UJTahIRqVXMArwEsKCTmJ2ZFKCLOohI+MQqwKcup1bTCFwBLiLhEq8ALy68hdIZbCl7XC0UEQmZWAX4VA98IfPAdRJTREIqVgFeSwslnUyQSyc5fkIjcBEJl3mTzMxuMbMBM3t02mPLzOznZrYn+NrX3DIbY6qFsoAROMDSzjRDGoGLSMhUk2TfAK6Y8dingbudc5uBu4P7oVfLNEKApZ0ZncQUkdCZN8mccw8Ax2Y8/A7g1uD2rcCVDa6rKfLBNMJ0qvqVmABLc2nNAxeR0Km1B77KOXcIIPi6cq4nmtk2M9thZjsGBwdrPFxj5IseyYSRtIUFeN8StVBEJHyafhLTOXeDc26rc25rf39/sw93SuMFj850EltggPfmMhqBi0jo1Brgh81sDUDwdaBxJTVPvuBNTQtciKWdaYbGtSOhiIRLrQF+J/CB4PYHgB80ppzmGi94U5tTLURfZ1o7EopI6FQzjfB24DfAWWZ2wMw+CHwReLOZ7QHeHNwPvXzRI5uuYQSeywBoLriIhEpqvic4594zx7cub3AtTZevcQS+tDMNlFdjrm90USIiNYrVSszxQmlqd8GFWNoZjMB1IlNEQiRWAZ4v+rW1UIIRuBbziEiYxCvAC6W6WiiaCy4iYRKrAK91FkrlJOaQTmKKSIjEKsBrnQeeSSVYkklqBC4ioRKvAC965GrogUP5RKZOYopImMQmwAsln5LvamqhAPTm0gzrJKaIhEhsArxyMYdcDdMIobyhlUbgIhIm8Qnw4GIONbdQchn1wEUkVGIT4OPBXuC1tlCWdqqFIiLhEqMAr7RQag/wobx2JBSR8IhNgFdaKDWPwHMZPN8xOllqZFkiIjWLT4AX6uyBV1ZjnlAbRUTCITYBXn8LJViNmddMFBEJh9gEeL5YOYlZ4zRCbWglIiETnwAv+ED9LRTNBReRsIhNgFemEdbaQukNNrQa1lxwEQmJ2AR45SRmPfPAzeDImEbgIhIOsQnw8aJHOmmkk7X9k9PJBCu6Ojg8PNHgykREahObAM8Xarug8XSre7IcGlGAi0g4xCrAa22fVKzuzWoELiKhEZsAHy96NU8hrFjdk+XQcL5BFYmI1Cc2AZ4v1H4xh4rVvVlGJkpTM1pERNqpviFphOSLpZqnEN724H4A9h05AcBNDzzLiu4Orr5oQ8PqExFZqNiMwGu9oPF0PbnyYp7hCc0FF5H2i02Aj02UWFJnD7w3Ww7wES3mEZEQiE2AD4xO0t/dUddrVEbgCnARCYNYBPhE0WM4X2RlnQGeSSXIphNqoYhIKMQiwI+MTQKwsqe+AAfoyaYZyWsWioi0XywCfGA0CPDubN2v1ZtLa0MrEQmFeAT4SDnA6+2BQ7kPPqIWioiEQF3TMsxsHzAKeEDJObe1EUU12uBoefl7vT1wKI/AxyZKeL4ubiwi7dWIhTxvcs4dacDrNM3g6CQJg+VdjemBO2BUo3ARabN4tFBGJ1ne1UEyYXW/Vm+u/JmnqYQi0m71BrgDfmZmO81sWyMKaoaB0cmGtE9g+mpMzUQRkfaqt4VyiXPuBTNbCfzczJ50zj0w/QlBsG8D2LChPXuHDDZgEU+FVmOKSFjUNQJ3zr0QfB0Avg9cOMtzbnDObXXObe3v76/ncDUbGJ1o2Ag8l0mSSpgCXETaruYAN7MlZtZduQ28BXi0UYU1iuc7jowVGjIHHMDM6MmltRpTRNqunhbKKuD7ZlZ5nduccz9pSFUNdOxEAc93DVmFWVFejakAF5H2qjnAnXN7gVc3sJamGAxWYfY3YAphxdLONM8MjuGcI/gAExFpuUU/jXCgsoingSPwTSuWMDpR4skXRxv2miIiCxWDAG/cPigVW1Z3A3DPkwMNe00RkYVa9AE+1UJp0CwUKPfAT1ua5V4FuIi0USwCvDubIlvnBY1nOmtVDw/tP87xE4WGvq6ISLUWfYA3cg74dGev7sZ3cP/uwYa/tohINRb9VekfOzhCMmFTV5ZvlLV9OVZ0ZbjnyQGuvGBtQ19bRKQai34EPjpZojvb+M+phBmXblnJ/bsHKXl+w19fRGQ+izrAnXOMThTpDvYvabTLz1nJcL7IV+95Gl/7g4tIiy3qAB+bLFH0XFNG4ABvPncVV55/Gl+9ew/b/mGnLrUmIi21qAO8Mge8WQGeTia4/s/P57q3nct9Tw1w+Zfu4xu/epZCSS0VEWm+RR3gjx4cBmBFA5fRz2RmXHPJGdzx8dfzipVdXPfDx3nL9fdz4Ph4044pIgKLfBbK/bsH6cwkOW1primvP3Nmy9vOO42zV/dwx0MHeN9ND/Kdj76+oQuIRESmW7QjcN93PLB7kM0ru0i0aMMpM2PLqm7ec+EGDg7ledv//iU3/+LZhk9hFBGBRRzgjx8a4chYgS2rult+7NOXL+F9F53OwOgEP33sxZYfX0TiYdEGeGWF5CtWdrXl+JtXdfO6jcvY8dwxjmm5vYg0weIN8KcG+aO1PU2bA16Ny85aScJMm16JSFMsygAfmSiyc/9xLt3SnmtwVvTm0lx4xjIefv44zx450dZaRGTxWZQB/uunj+D5jku3rGx3KVy6pZ9kwvjKXbvbXYqILDKLMsDveXKA7o4UF2xY2u5S6M6muXjTcn7w+xfYc7i5V/DxfMeB4+M49/Jl/UPjBX78yCFeHJ5oag0i0jqLbh54oeTz08cOc/k5K0knw/H59MbN/Tz03HH+1117+Np7X9Pw1//8j5/gwWePsufwGPmiR28uzbmn9dDXmaHo+bw4PMETh0Yo+Y500vjYpWey7dIz6epYdP/5RWJl0f0f/KunjzCcL/Lvzjut3aVMWdKR4i8uOYO/u/dpPvHCCOee1tOw1/7W9ue4+Zd7yaWTnL26m9OW5tg7OMbvnj1GKdhgK5dO8rqNyzh7TTc79h3nq/c8zc8eP8z3P34JuUxjL3QhIq2z6AL8h4+8QHc2xRu2rGh3KSf58Bs2cetv9nH9Xbu58T9trfv1PN/x+R8/wS2/epazVnVz1evW0xFcdeiSV6yg6Pl4viOdTJBMvLSQafPKbj7Z3cGHvrmDv/nR43zh37+q7lpEpD0WTYDf9uB+ip7Pjx85xCtP6+V7Ow+2u6ST9Ham+fAbNvHln+9m+96jXLxpec2vNTZZ4pO3P8zdTw5wzes3cmZ/10khDeWNtua6itzA6CSXbunn9t/uxznHeevK5wquvmhDzTWJSOuFo0ncIHsOjzFZ8jlvXW+7S5nVB//kDDYu7+Svvr2L4fGFbz3r+46dzx3j3V//DfftHuRz73gl1739lS8L72r82TmrWN+X4/sPH2RgVCc2RaJo0YzAAR45OERnJsmZ/e1ZfXkqlf1Q3vqqNXz9/me4+qbtXH3hBt578ekAjBdKfP/hgzzy/DC7B0Y5MlbeCjdhRm8uTW8uzROHyo93pBK8/+LTSSYSNe+zkkwYV124gf9z3zN849f7+OilZzbmHyoiLbNoAnyy6PHkoVFevb63phFpq6zr6+Qt567mJ4+9yHd2HsAHRieK3PyLZzl6osCyJRm2rOpi+ZIODPCcY6LocXSswJreLJefvZKzVneTnas/sgB9nRmu+eON3PiLvdz6632896INbV25KiILs2gCfNeBIQqez2tPX9buUub1J5tXMDg6yaMvDPPX/+9RADav7OJdr13H6cuXtLSWtX05rr5oA9/8zT7+zfUPcO2fbuZdr11HOmnBtMNF1WUTWVRstkUfzbJ161a3Y8eOhr+uc44//sI9mMG1b3oF1qLtY+vlnGM4X6TkOVa0ed/wvYNj7HjuOLueHyKTSlDyfHxXvprR2qU5tm7s42OXvYK1TdpbXUTmZmY7nXMvm762KEbgD+0/zosjE1x5/trIhDeU9w9f2plpdxkAbOrv4rP/9hzue2qQXz19hGw6SUcqwZGxSbbvPcbtv32e23/7PBduXMalZ/WrZy4SAosiwL+1fT8dqQSvXh/O2SdRcftvnwfKYV6xvKuDs1b3MDRe4N6nBnjw2aNTW+Re8/qNTbvakYjML/IBfuxEeY+P15zeR0dKqwqbZWlnhndesI43bu7nnicHuPEXe7nhgb28am0vb9i8gnV9nazpzbJmaZY1vTl6sqlI/TYkEkWRDnDPd/z1Dx6l4PlcdEb4T14uBsu7Onj31vVc/+fn86+PvsjPHn+Rr9//DP6MUymn9Wb503NWctmWlZy3vpeV3dkFH6vo+YxOlBibKDEyUSRf9FiaS7OyO0tPTh8QInWdxDSzK4CvAEngJufcF0/1/EaexHSuHN7f2r6fz7z1bLo6NP2tXTzfMTpRZCRfZChfZDhf5Lmj4zw9MEbB8wFY0ZWhO5vG8x2e7/DdyV/Lt8uvVfR8fOde9qEwXVdHik39S9iwrJPOTJJMKsF4wWN4vEjJd6zo6mBlTwfnr1/KxWcsp7fz5T8fvu8YnSxhBj2aPikh1vCTmGaWBL4GvBk4APzOzO50zj1ee5mn5pxjJF9ix3PH+PEjh7jj4YN85NJNbHvjmbpwcBslE+WTsUs7M1QW479hc3kE/fzxcQ4NTXB4ZIKC55MwwygvUDI7+WvCyid2K1/TyQTZdIJsKkk2nSCdLIf0yESR4+MFjowW+M0zRyl6PiXfkUkmyGWSJMzY9fwQ44USRc9hBuv6cqzqztKVTXF4ZJJDw3mG80Uq45fKbJt1fZ2s68uRyySZKHqM5EvsO3qC546eYLJY/jDqSCfL7aLeLGf0L+HM/i7W93XS391BX2e67otoFz2fEwWP8UIJw0gmyu9JImEkLbifMFKJ8nuUShrpRHnPG893FDyfkudT9NzUe1PyfDKp8vvTmUmRSyerXi/hnKPkOwoln8mSH3z1KJR8POfIpZPk0kk6gq/JhJ103JLvMCCVTJBOGqlE+WtYf4OaOaidfrfkOyZKHhNFj8miz0TRA6AjVR5EdKQSZFLln9VU8N+pmeppoVwIPO2c2wtgZv8EvANoeIB/7keP8w/bn6NQ8qcey6QS/MUlG/n0FWc3+nDSIOlkgk0ruti0oj0rY0uez4HjefYeGePIWIFjJwq8MJSnO5tmy6pulmRS5NIJHHB8vMjQeIE/HBzigT2DeJ4jlTSy6STLlmTYuHwJHanynPjJks/IRJFdzw9x95MDeKf6VSHEMskEzMyXWf4pJd8/5W9DtUoGH0LTP/DctAKmB+dJhz/p8fmfPz2QT3584TUvVMIglSh/yH79fa/ljQ2+SljNLRQzexdwhXPuQ8H99wMXOeeunfG8bcC24O5ZwFO1lwvACuBIna/RKqq1OaJUK0SrXtXaHPXWerpz7mXpX88IfLbfDV72aeCcuwG4oY7jnHxQsx2z9YLCSLU2R5RqhWjVq1qbo1m11rNO+gCwftr9dcAL9ZUjIiLVqifAfwdsNrMzzCwDXAXc2ZiyRERkPjW3UJxzJTO7Fvgp5WmEtzjnHmtYZXNrWDumBVRrc0SpVohWvaq1OZpSa0s3sxIRkcbRXqEiIhGlABcRiajQBriZXWFmT5nZ02b26Vm+32Fm3w6+/6CZbWx9lVO1zFfrG83sITMrBfPn26aKWv/KzB43s0fM7G4zO70ddQa1zFfrR83sD2a2y8x+aWbntqPOoJZT1jrtee8yM2dmbZv+VsX7eo2ZDQbv6y4z+1A76gxqmfd9NbP/GPzMPmZmt7W6xhm1zPfeXj/tfd1tZkN1HdA5F7o/lE+KPgNsAjLA74FzZzzn48DXg9tXAd8Oca0bgfOAbwLvCvn7+iagM7j9sZC/rz3Tbr8d+ElYaw2e1w08AGwHtoa1VuAa4O/aUV8NtW4GHgb6gvsrw1zvjOf/Z8qTP2o+ZlhH4FPL9J1zBaCyTH+6dwC3Bre/C1xu7dlcYd5anXP7nHOPAP5sL9BC1dR6r3NuPLi7nfL8/naoptaRaXeXMOtC8Jao5ucV4HPA/wAmWlncDNXWGgbV1Pph4GvOueMAzrmBFtc43ULf2/cAt9dzwLAG+Frg+Wn3DwSPzfoc51wJGAaWt6S6OeoIzFZrWCy01g8C/9rUiuZWVa1m9gkze4ZyMP6XFtU207y1mtkFwHrn3I9aWdgsqv0Z+A9BG+27ZrZ+lu+3QjW1bgG2mNmvzGx7sENqu1T9/1fQmjwDuKeeA4Y1wKtZpl/VUv4WCEsd1ai6VjN7H7AV+NumVjS3ardq+Jpz7kzgvwL/relVze6UtZpZArge+FTLKppbNe/rD4GNzrnzgLt46TfdVqum1hTlNspllEe0N5nZ0ibXNZeFZMFVwHedc149BwxrgFezTH/qOWaWAnqBYy2pbo46AmHeUqCqWs3sz4DPAm93zk22qLaZFvq+/hNwZVMrmtt8tXYDfwTcZ2b7gIuBO9t0InPe99U5d3Taf/cbgde2qLaZqs2BHzjnis65Zylvlre5RfXNtJCf2auos30ChPYkZgrYS/lXjMrJgFfOeM4nOPkk5j+HtdZpz/0G7T2JWc37egHlEzGbI/AzsHna7bcBO8Ja64zn30f7TmJW876umXb7ncD2ENd6BXBrcHsF5RbG8rDWGzzvLGAfwULKuo7Zjn9olW/GW4HdQZh8NnjsbyiPCgGywHeAp4HfAptCXOvrKH86nwCOAo+FuNa7gMPAruDPnSGu9SvAY0Gd954qNNtd64znti3Aq3xfvxC8r78P3tezQ1yrAV+mfB2CPwBXtavWan8OgOuALzbieFpKLyISUWHtgYuIyDwU4CIiEaUAFxGJKAW4iEhEKcBFRCJKAS4iElEKcBGRiFKAS6yZ2efM7JPT7n/ezNq1KZbIgmghj8RacCGQO5xzrwk2ndoDXOicO9rWwkSqUPNV6UUWA+fcPjM7Gmz3ugp4WOEtUaEAF4GbKF+FZjVwS3tLEameWigSe2aWobwRUpryDod17dEs0ioagUvsOecKZnYvMKTwlihRgEvsBScvLwbe3e5aRBZC0wgl1szsXMp7yt/tnNvT7npEFkI9cBGRiNIIXEQkohTgIiIRpQAXEYkoBbiISEQpwEVEIur/AzAPnAZUHl9zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################################################################################\n",
    "# импортируем данные\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.shape # (3865, 80)\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.shape # (890, 79)\n",
    "df_sample_submit = pd.read_csv('sample_submit.csv')\n",
    "df_sample_submit.shape # (890, 3)\n",
    "\n",
    "\n",
    "# смотрим уникальные звёзды в тренировке и тесте\n",
    "galaxies_train = set(df_train.galaxy)\n",
    "galaxies_test = set(df_test.galaxy)\n",
    "\n",
    "galaxies_test - galaxies_train # set()\n",
    "galaxies_train - galaxies_test # {'Andromeda XXIV', 'Andromeda XVIII[60]', 'Triangulum Galaxy (M33)',\n",
    "# 'Andromeda XXII[57]', 'Tucana Dwarf', 'Andromeda XII', 'Andromeda XIX[60]', 'NGC 5253', 'Hercules Dwarf'}\n",
    "\n",
    "galaxies_train_dict = Counter(df_train.galaxy)\n",
    "galaxies_train_dict.most_common()\n",
    "\n",
    "# в тренировке больше звёзд, это хорошо, попробуем использовать дамми звёзд\n",
    "dummy_train = pd.get_dummies(df_train['galaxy'])\n",
    "df_train = pd.concat([df_train, dummy_train], axis = 1)\n",
    "df_train.drop(columns='galaxy', inplace=True)\n",
    "\n",
    "dummy_test = pd.get_dummies(df_test['galaxy'])\n",
    "df_test = pd.concat([df_test, dummy_test], axis = 1)\n",
    "df_test.drop(columns='galaxy', inplace=True)\n",
    "\n",
    "# уберём целевую переменную\n",
    "y_train = df_train['y']\n",
    "X_train = df_train.drop(columns = ['y'])\n",
    "X_train.shape # (3865, 259)\n",
    "df_test.shape # (890, 250)\n",
    "\n",
    "# дозаполним отсутсвующими столбцами\n",
    "X_test = df_test.copy()\n",
    "for col in list(galaxies_train - galaxies_test):\n",
    "    X_test[col] = 0\n",
    "\n",
    "X_test.shape # (890, 259)\n",
    "\n",
    "# посмотрим, какая у нас целевая переменная\n",
    "y_train.describe()\n",
    "sns.distplot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "# Проверка разных imputers -- сошлись на BayesianRidge\n",
    "\n",
    "# good_imputer = IterativeImputer(random_state = 0, estimator = BayesianRidge())\n",
    "# X_train_f = good_imputer.fit_transform(X_train)\n",
    "# pd.DataFrame(X_train_f).to_csv(\"BayesianRidge_X_train.csv\", index = False)\n",
    "\n",
    "X_train_fill = pd.read_csv(\"BayesianRidge_X_train.csv\")\n",
    "\n",
    "# Дальше экспериментируем с параметрами для лучших алгоритмов\n",
    "\n",
    "estimators = [\n",
    "    ElasticNet(),\n",
    "    AdaBoostRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    HistGradientBoostingRegressor(),\n",
    "    XGBRegressor()\n",
    "]\n",
    "\n",
    "# лист гиперпараметров\n",
    "tuned_parameters = [\n",
    "    # {'normalize': [True], 'alpha': np.logspace(-10, 1, 50), 'l1_ratio': [0, .1, .5, .7, .9, .95, .99, 1], 'max_iter': [2000]}, # всегда нормируем !!!\n",
    "    # {'alpha': 8.68511373751352e-06, 'l1_ratio': 0.1, 'max_iter': 2000, 'normalize': True} -- намёк на лишние переменные, а может и нет\n",
    "    {'normalize': [True], 'alpha': [8.68511373751352e-06], 'l1_ratio': [0.1], 'max_iter': [2000]},\n",
    "    # {'n_estimators': [10, 20, 30, 40, 50, 60, 70], 'random_state': [0]},\n",
    "    # {'n_estimators': 20, 'random_state': 0}\n",
    "    {'n_estimators': [15, 20, 25], 'random_state': [0]},\n",
    "    # {'n_estimators': [200, 300], 'random_state': [0], 'max_depth': [*range(18, 20)]},\n",
    "    # всегда росло с 2 до 18 для n_estimators = 200, поэтому гляну дальше\n",
    "    {'n_estimators': [250], 'random_state': [0], 'max_depth': range(18, 21, 1)},\n",
    "    {'max_iter': [250], 'random_state': [0], 'max_depth': [11]},\n",
    "    # были проверены все глубины меньше и больше, остановлюсь на 11\n",
    "    {'n_estimators': [250], 'min_child_weight': range(1, 6, 2), 'gamma': [0.5, 1.0], 'subsample': [0.8, 1.0], \\\n",
    "    'colsample_bytree': [0.7, 1.0], 'random_state': [0], 'max_depth': range(3, 10, 2)}\n",
    "    #\n",
    "]\n",
    "\n",
    "# пытаемся улучшить предсказание поиском лучших параметров (пока среди тех комбинаций и алгоритмов)\n",
    "i = 0\n",
    "all_info = [np.nan for i in range(len(estimators))]\n",
    "grid_scores = [np.inf for i in range(len(estimators))]\n",
    "best_params = [np.nan for i in range(len(estimators))]\n",
    "\n",
    "for t, br_estimator in enumerate(estimators):\n",
    "    time = datetime.now()\n",
    "    print(\"Estimator: {}\".format(br_estimator.__class__.__name__))\n",
    "    clf = GridSearchCV(br_estimator, tuned_parameters[t])\n",
    "    clf.fit(X_train_fill, y_train)\n",
    "    all_info[i] = clf.cv_results_\n",
    "    grid_scores[i] = clf.best_score_\n",
    "    print(grid_scores[i])\n",
    "    best_params[i] = clf.best_params_\n",
    "    print(best_params[i])\n",
    "    i += 1\n",
    "    print(\"Time: {}\".format(datetime.now() - time))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################################################\n",
    "X_train_f = pd.read_csv(\"BayesianRidge_X_train.csv\")\n",
    "\n",
    "# вроде как лучшие\n",
    "k_f = KFold(n_splits = 10, shuffle = True, random_state = 0)\n",
    "\n",
    "# неожиданный и простой король -- эластичная сеть\n",
    "algo_1 = ElasticNetCV(l1_ratio = 0.1, normalize = True, max_iter = 1500) # adaboost ломает его!\n",
    "algo_1_score = cross_val_score(algo_1, X_train_f, y_train, scoring = 'r2', cv = k_f)\n",
    "np.round(np.mean(algo_1_score), 3) # 0.942\n",
    "# algo_1_score = cross_val_score(algo_1, X_train_f, y_train, scoring = 'neg_mean_squared_error', cv = k_f) среднеквадратическая ошибка -- 0.000243\n",
    "\n",
    "# не неожиданный лес\n",
    "algo_2 = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "algo_2_score = cross_val_score(algo_2, X_train_f, y_train, scoring = 'r2', cv = k_f)\n",
    "np.round(np.mean(algo_2_score), 3) # 0.917\n",
    "\n",
    "# также не неожиданный бустинг\n",
    "algo_3 = HistGradientBoostingRegressor(max_depth = 11, max_iter = 500, random_state = 0)\n",
    "algo_3_score = cross_val_score(algo_3, X_train_f, y_train, scoring = 'r2', cv = k_f)\n",
    "np.round(np.mean(algo_3_score), 3) # 0.899 (раньше было 0.9, без фикс глубины, решил ограничить, мб позволит не переобучаться)\n",
    "\n",
    "\n",
    "# попробуем их всех объединить\n",
    "estims = [\n",
    "    ('RF', RandomForestRegressor(n_estimators = 100, random_state = 0)),\n",
    "    ('GB', HistGradientBoostingRegressor(max_depth = 11, max_iter = 500, random_state = 0))\n",
    "]\n",
    "\n",
    "# лес и бустинг генерирует даннные, на них обучаем эластичную сеть (эластичная сеть и бустинг генерирует даннные, на них обучаем лес -- плохо)\n",
    "reg = StackingRegressor(estimators = estims, final_estimator = ElasticNetCV(l1_ratio = 0.1, normalize = True, max_iter = 1500), passthrough = True)\n",
    "reg_score = cross_val_score(reg, X_train_f, y_train, scoring = 'r2', cv = k_f)\n",
    "np.round(np.mean(reg_score), 3) # 0.952 -- пока что предел\n",
    "\n",
    "\n",
    "###############################################################################################################################################\n",
    "# МИНИ ТЕСТ на тренировочной выборке с лучшими: заполнитель - BayesianRidge, оценщик - Stacking\n",
    "X_train_betta, X_test_betta, y_train_betta, y_test_betta = train_test_split(X_train, y_train, train_size = 0.8, random_state = 0)\n",
    "\n",
    "good_imputer = IterativeImputer(random_state = 0, estimator = BayesianRidge())\n",
    "good_imputer.fit(X_train_betta)\n",
    "X_train_betta_f = good_imputer.transform(X_train_betta)\n",
    "X_test_betta_f = good_imputer.transform(X_test_betta)\n",
    "\n",
    "estims = [\n",
    "    ('RF', RandomForestRegressor(n_estimators = 100, random_state = 0)),\n",
    "    ('GB', HistGradientBoostingRegressor(max_iter = 500, random_state = 0))\n",
    "]\n",
    "\n",
    "reg = StackingRegressor(estimators = estims, final_estimator = ElasticNetCV(l1_ratio = 0.1, normalize = True, max_iter = 1500), passthrough = True)\n",
    "reg.fit(X_train_betta_f, y_train_betta)\n",
    "\n",
    "y_train_pred_betta = reg.predict(X_train_betta_f)\n",
    "y_test_pred_betta = reg.predict(X_test_betta_f)\n",
    "\n",
    "r2_train_betta = r2_score(y_train_betta, y_train_pred_betta)\n",
    "rmse_train_betta = mean_squared_error(y_train_betta, y_train_pred_betta, squared = False)\n",
    "\n",
    "print(\"R2: {0:.3f}, RMSE: {1:.5f}\".format(r2_train_betta, rmse_train_betta)) # R2: 0.978, RMSE: 0.00904\n",
    "\n",
    "r2_test_betta = r2_score(y_test_betta, y_test_pred_betta)\n",
    "rmse_test_betta = mean_squared_error(y_test_betta, y_test_pred_betta, squared = False)\n",
    "\n",
    "print(\"R2: {0:.3f}, RMSE: {1:.5f}\".format(r2_test_betta, rmse_test_betta)) # R2: 0.922, RMSE: 0.01982\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################################################\n",
    "\n",
    "# Первая часть - предсказываем индекс\n",
    "good_imputer = IterativeImputer(random_state = 0, estimator = BayesianRidge())\n",
    "good_imputer.fit(X_train)\n",
    "X_train_f = good_imputer.transform(X_train)\n",
    "X_test_f = good_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estims = [\n",
    "    ('RF', RandomForestRegressor(n_estimators = 100, random_state = 0)),\n",
    "    ('GB', HistGradientBoostingRegressor(max_iter = 500, random_state = 0))\n",
    "]\n",
    "\n",
    "reg = StackingRegressor(estimators = estims, final_estimator = ElasticNetCV(l1_ratio = 0.1, normalize = True, max_iter = 1500), passthrough = True)\n",
    "reg.fit(X_train_f, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test_f)\n",
    "df_sample_submit[\"pred\"] = y_pred\n",
    "\n",
    "(y_pred < 0).sum() # 10 штучек, заменим их на 0\n",
    "y_pred.describe()\n",
    "sns.distplot(y_pred)\n",
    "plt.show()\n",
    "\n",
    "df_sample_submit.loc[y_pred < 0, \"pred\"] = 0\n",
    "df_sample_submit.pred.describe()\n",
    "sns.distplot(df_sample_submit.pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.DataFrame(X_train_f, columns=X_train.columns)\n",
    "target = y_train\n",
    "test = pd.DataFrame(X_test_f, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning parasmeters according to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "#Choose all predictors except target & IDcols\n",
    "#Порядок насройки параметров определён из матерниалов сайта\n",
    "xgb1 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "             n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "             silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8230277402972514e-06"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(xgb1.predict(X_train_f), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = xgb1.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 7, 'min_child_weight': 1}, 0.8986818469764097)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1,n_jobs=4,cv=5)\n",
    "gsearch1.fit(X_train_f, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "\n",
    "#({'max_depth': 7, 'min_child_weight': 1}, 0.8986818469764097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем дополнительную вариацию (на  соседние значения параметров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 7, 'min_child_weight': 1}, 0.8986818469764097)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[6,7,8],\n",
    " 'min_child_weight':[1,2]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBRegressor( learning_rate=0.1, n_estimators=140, max_depth=7,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2,n_jobs=4, cv=5)\n",
    "gsearch2.fit(X_train_f, y_train)\n",
    "gsearch2.best_params_, gsearch2.best_score_\n",
    "\n",
    "#({'max_depth': 7, 'min_child_weight': 1}, 0.8986818469764097) всё равно получаем такой результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.0}, 0.8986818469764097)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=7,\n",
    " min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3,n_jobs=4, cv=5)\n",
    "gsearch3.fit(X_train_f, y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "#({'gamma': 0.0}, 0.8986818469764097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimum\n",
    "#max_depth = 7\n",
    "#min_child_weight = 1\n",
    "#gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.6, 'subsample': 0.9}, 0.9009301067017615)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4,n_jobs=4, cv=5)\n",
    "gsearch4.fit(X_train_f, y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.55, 'subsample': 0.95}, 0.903412903967034)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проведём вариацию параметров вокруг полученного варианта\n",
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(85,100,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(55,70,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    " min_child_weight=1, gamma=0,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, n_jobs=4, cv=5)\n",
    "gsearch5.fit(X_train_f, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimum\n",
    "#colsample_bytree = 0.55\n",
    "#subsample = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 1e-05}, 0.9035422326887461)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    " min_child_weight=1, gamma=0, subsample=0.95, colsample_bytree=0.55,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6,n_jobs=4, cv=5)\n",
    "gsearch6.fit(X_train_f, y_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_\n",
    "\n",
    "#({'reg_alpha': 1e-05}, 0.9035422326887461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=7,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.95,\n",
    " colsample_bytree=0.55,\n",
    " reg_alpha=0.00001,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.55, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "             n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "             reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, seed=27,\n",
       "             silent=None, subsample=0.95, verbosity=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb3.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0661840155051792e-07"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(xgb3.predict(X_train_f), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = xgb3.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=7,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.95,\n",
    " colsample_bytree=0.55,\n",
    " reg_alpha=0.00001,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "xgb4.fit(X_train_f, y_train)\n",
    "mean_squared_error(xgb4.predict(X_train_f), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = xgb4.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submit[\"pred\"] = y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "\n",
    "# Вторая часть - оптимизируем количество энергии по галактикам\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# начальная догадка параметров\n",
    "extra_energy = np.array(df_sample_submit['opt_pred'])\n",
    "\n",
    "# на какой вектор умножаем\n",
    "potential_increase_in_index = - np.log(df_sample_submit.pred + 0.01) + 3\n",
    "likely_increase_in_index_part = potential_increase_in_index ** 2 / 1000\n",
    "\n",
    "# итоговая функция для минимизации (ставим в одном из векторов минус, получается типо максимизация :) )\n",
    "likely_increase_in_index = lambda likely_increase_in_index_part, extra_energy: np.dot(extra_energy, -likely_increase_in_index_part)\n",
    "\n",
    "# понадобится для ограничения:\n",
    "# Galaxies with low existence expectancy index below 0.7 should be allocated at least 10% of the total energy available in the foreseeable future\n",
    "existence_expectancy_index_bool = (X_test_f[:, 1] < 0.7).astype(int)\n",
    "\n",
    "# ограничения\n",
    "cons = ({'type': 'ineq',\n",
    "            'fun': lambda existence_expectancy_index_bool, extra_energy: np.dot(existence_expectancy_index_bool, extra_energy) - 5000,\n",
    "            'jac': lambda existence_expectancy_index_bool, extra_energy: existence_expectancy_index_bool,\n",
    "            'args': (existence_expectancy_index_bool, )},\n",
    "        {'type': 'ineq',\n",
    "            'fun': lambda extra_energy: np.sum(extra_energy) - 50000,\n",
    "            'jac': lambda extra_energy: np.ones(len(extra_energy))})\n",
    "\n",
    "# запускаем минимизацию\n",
    "res = minimize(fun = likely_increase_in_index, x0 = extra_energy, args = (likely_increase_in_index_part, ), \\\n",
    "                jac = lambda likely_increase_in_index_part, extra_energy: likely_increase_in_index_part, \\\n",
    "                bounds = [(0, 100) for i in range(890)], method = 'SLSQP', constraints = cons, options = {'maxiter': 10000})\n",
    "\n",
    "res.x\n",
    "np.dot(res.x, -likely_increase_in_index_part)\n",
    "np.dot(existence_expectancy_index_bool, res.x)\n",
    "\n",
    "# ну, для первой попытки можно попробовать\n",
    "df_sample_submit[\"opt_pred\"] = res.x\n",
    "\n",
    "df_sample_submit.to_csv(\"Attempt_simple_xgboost.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submit[\"pred\"] = y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "\n",
    "# Вторая часть - оптимизируем количество энергии по галактикам\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# начальная догадка параметров\n",
    "extra_energy = np.array(df_sample_submit['opt_pred'])\n",
    "\n",
    "# на какой вектор умножаем\n",
    "potential_increase_in_index = - np.log(df_sample_submit.pred + 0.01) + 3\n",
    "likely_increase_in_index_part = potential_increase_in_index ** 2 / 1000\n",
    "\n",
    "# итоговая функция для минимизации (ставим в одном из векторов минус, получается типо максимизация :) )\n",
    "likely_increase_in_index = lambda likely_increase_in_index_part, extra_energy: np.dot(extra_energy, -likely_increase_in_index_part)\n",
    "\n",
    "# понадобится для ограничения:\n",
    "# Galaxies with low existence expectancy index below 0.7 should be allocated at least 10% of the total energy available in the foreseeable future\n",
    "existence_expectancy_index_bool = (X_test_f[:, 1] < 0.7).astype(int)\n",
    "\n",
    "# ограничения\n",
    "cons = ({'type': 'ineq',\n",
    "            'fun': lambda existence_expectancy_index_bool, extra_energy: np.dot(existence_expectancy_index_bool, extra_energy) - 5000,\n",
    "            'jac': lambda existence_expectancy_index_bool, extra_energy: existence_expectancy_index_bool,\n",
    "            'args': (existence_expectancy_index_bool, )},\n",
    "        {'type': 'ineq',\n",
    "            'fun': lambda extra_energy: np.sum(extra_energy) - 49999,\n",
    "            'jac': lambda extra_energy: np.ones(len(extra_energy))})\n",
    "\n",
    "# запускаем минимизацию\n",
    "res = minimize(fun = likely_increase_in_index, x0 = extra_energy, args = (likely_increase_in_index_part, ), \\\n",
    "                jac = lambda likely_increase_in_index_part, extra_energy: likely_increase_in_index_part, \\\n",
    "                bounds = [(0, 100) for i in range(890)], method = 'SLSQP', constraints = cons, options = {'maxiter': 10000})\n",
    "\n",
    "res.x\n",
    "np.dot(res.x, -likely_increase_in_index_part)\n",
    "np.dot(existence_expectancy_index_bool, res.x)\n",
    "\n",
    "# ну, для первой попытки можно попробовать\n",
    "df_sample_submit[\"opt_pred\"] = res.x\n",
    "\n",
    "df_sample_submit.to_csv(\"Attempt_tuned_xgboost.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>opt_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>89.237660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038081</td>\n",
       "      <td>89.237660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>89.237660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>89.237660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>89.237660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>27.800489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>0.028539</td>\n",
       "      <td>27.800489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>27.800489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>27.800489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>27.800489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index      pred   opt_pred\n",
       "0        0  0.040923  89.237660\n",
       "1        1  0.038081  89.237660\n",
       "2        2  0.037769  89.237660\n",
       "3        3  0.040449  89.237660\n",
       "4        4  0.021740  89.237660\n",
       "..     ...       ...        ...\n",
       "885    885  0.026949  27.800489\n",
       "886    886  0.028539  27.800489\n",
       "887    887  0.037344  27.800489\n",
       "888    888  0.033491  27.800489\n",
       "889    889  0.027363  27.800489\n",
       "\n",
       "[890 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"Attempt_tuned_xgboost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
